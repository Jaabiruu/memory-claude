# @REFLECT Mode - Quality & Validation

**Mode Purpose**: Critical analysis, quality assessment, and comprehensive validation
**Position**: Required validation phase for all complexity levels
**Think Tool Usage**: Comprehensive quality assessment and improvement identification

## Mode Objectives

### Primary Goals
1. **Quality Assessment**: Comprehensive evaluation of implementation quality
2. **Validation Testing**: Thorough testing against all requirements
3. **Performance Analysis**: Evaluate performance, scalability, and efficiency
4. **Code Review**: Detailed review of code quality and maintainability
5. **Improvement Identification**: Identify areas for enhancement and optimization

### Success Criteria
- [ ] Comprehensive quality assessment completed
- [ ] All requirements validated and verified
- [ ] Performance benchmarks met and documented
- [ ] Code quality review completed with recommendations
- [ ] Improvement plan created for identified issues

## REFLECT Mode Instructions

### Phase 1: Comprehensive Testing
**Use Think Tool for systematic quality assessment:**

1. **Functional Testing**
   - Validate all functional requirements are met
   - Test all user scenarios and use cases
   - Verify error handling and edge cases
   - Validate integration points and dependencies

2. **Non-Functional Testing**
   - Performance testing and benchmarking
   - Security testing and vulnerability assessment
   - Usability testing and user experience validation
   - Compatibility testing across environments

3. **Regression Testing**
   - Verify existing functionality still works
   - Test impact of changes on related systems
   - Validate no unintended side effects
   - Ensure backward compatibility where required

### Phase 2: Code Quality Review
**Detailed code analysis and review:**

1. **Code Structure Analysis**
   - Review code organization and architecture
   - Assess adherence to design patterns
   - Evaluate code readability and maintainability
   - Check for code duplication and refactoring opportunities

2. **Technical Debt Assessment**
   - Identify technical debt and shortcuts taken
   - Assess impact of technical debt on maintainability
   - Prioritize technical debt remediation
   - Plan for future refactoring activities

3. **Documentation Review**
   - Verify code documentation completeness
   - Review API documentation accuracy
   - Validate user documentation and guides
   - Ensure architectural documentation is current

### Phase 3: Performance Analysis
**Evaluate system performance and efficiency:**

1. **Performance Benchmarking**
   - Measure response times and throughput
   - Analyze resource utilization patterns
   - Identify performance bottlenecks
   - Compare against performance requirements

2. **Scalability Assessment**
   - Evaluate system scalability characteristics
   - Test load handling capabilities
   - Assess resource scaling requirements
   - Identify scalability limitations

3. **Optimization Opportunities**
   - Identify optimization opportunities
   - Assess cost-benefit of optimizations
   - Plan performance improvement strategies
   - Document optimization recommendations

### Phase 4: Improvement Planning
**Create comprehensive improvement plan:**

1. **Issue Prioritization**
   - Categorize identified issues by severity
   - Assess impact on users and system
   - Prioritize fixes based on risk and effort
   - Plan remediation timeline

2. **Enhancement Opportunities**
   - Identify enhancement opportunities
   - Assess value and effort for enhancements
   - Plan future development iterations
   - Document feature requests and improvements

3. **Maintenance Planning**
   - Plan ongoing maintenance activities
   - Identify monitoring and alerting needs
   - Plan backup and disaster recovery
   - Document operational procedures

### Phase 5: Session Discovery Evaluation
**Apply intelligent curation to reflection discoveries:**

1. **Discovery Identification**
   - Extract patterns discovered during quality assessment
   - Identify solutions found for performance and quality issues
   - Document debugging techniques and approaches used
   - Capture architectural insights and decisions made

2. **Automatic Evaluation**
   - Apply evaluation engine to each discovery
   - Score based on novelty, reusability, impact, generalizability, validation
   - Use Think tool for complex evaluation scenarios
   - Generate suggested inclusion/exclusion decisions

3. **Curation Decision Processing**
   - Auto-include high-scoring discoveries (above category thresholds)
   - Queue borderline items for manual review with full context
   - Auto-exclude low-quality items with documented rationale
   - Update curation log with all decisions and reasoning

## Required Outputs

### File Updates
1. **tasks.md** (SACRED - Update)
   - Mark implementation tasks as complete
   - Add identified improvement tasks
   - Update task priorities based on findings
   - Document validation and testing tasks

2. **activeContext.md**
   - Shift focus to quality and validation
   - Document critical issues found
   - Update priorities based on assessment
   - Note improvement planning activities

3. **progress.md**
   - Update with reflection phase progress
   - Document quality assessment results
   - Record performance benchmarks
   - Update milestone completion status

### Assessment Artifacts
4. **Create quality-assessment.md**
   - Comprehensive quality evaluation results
   - Testing outcomes and validation results
   - Performance benchmarks and analysis
   - Code quality review findings

5. **Create improvement-plan.md**
   - Prioritized list of issues and improvements
   - Remediation strategies and timelines
   - Enhancement opportunities and planning
   - Maintenance and operational recommendations

6. **Create testing-report.md**
   - Detailed testing results and coverage
   - Performance testing outcomes
   - Security assessment results
   - User acceptance testing feedback

### Context Window Management
- Monitor context during comprehensive assessment
- Preserve quality findings and recommendations
- Document improvement strategies and decisions

## Exit Criteria

### Mandatory Requirements
- [ ] Comprehensive quality assessment completed
- [ ] All critical issues identified and documented
- [ ] Performance benchmarks completed and analyzed
- [ ] Code quality review finished with recommendations
- [ ] Improvement plan created and prioritized
- [ ] **Session discoveries evaluated using curation engine**
- [ ] **High-quality discoveries stored in knowledge base**
- [ ] **Borderline discoveries queued for manual review**

### Quality Gates
- [ ] Think Tool used for systematic quality assessment
- [ ] All requirements validated against implementation
- [ ] Performance requirements met or exceptions documented
- [ ] Critical issues have remediation plans
- [ ] Quality standards maintained throughout assessment
- [ ] **Curation decisions logged with rationales**
- [ ] **Quality thresholds applied to all discoveries**

### Validation Checklist
- [ ] Functional requirements fully validated
- [ ] Non-functional requirements assessed
- [ ] Security requirements verified
- [ ] Performance requirements benchmarked
- [ ] User acceptance criteria met
- [ ] **Discovery evaluation completed using multi-criteria scoring**
- [ ] **Curation queue updated with review items**

## Next Mode Transition

**Based on Complexity Level:**
- **Level 1-2**: Project completion or iteration
- **Level 3-4**: Proceed to @ARCHIVE mode

**Transition Command**: `!@ARCHIVE` or project completion

## Context Preservation Notes

### Critical Information
- Quality assessment results and findings
- Performance benchmarks and analysis
- Improvement recommendations and priorities
- Testing outcomes and validation results
- Code quality review findings

### Knowledge Extraction with Intelligent Curation
- Quality assessment methodologies → **Auto-evaluate** for patterns-learned.md
- Testing strategies and techniques → **Auto-evaluate** for testing-approaches.md
- Performance analysis approaches → **Auto-evaluate** for solutions-found.md
- Code review best practices → **Auto-evaluate** for patterns-learned.md
- Improvement planning processes → **Auto-evaluate** for decisions-made.md

**Automatic Evaluation Process:**
1. **Extract Discoveries**: Identify patterns, solutions, and insights from reflection
2. **Apply Curation Engine**: Score discoveries using 5-criteria evaluation framework
3. **Process Decisions**: Auto-include high-quality items, queue borderline cases for review
4. **Update Curation Log**: Track all evaluation decisions and rationales

---
**REFLECT Mode Complete**: Quality assessment and validation finished
**Context Status**: Quality findings preserved
**Next Action**: Proceed to @ARCHIVE mode or complete project based on complexity